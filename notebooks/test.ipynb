{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['imputation_rules', 'deduplication_rules', 'replacement_rules'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "\n",
    "path = 'C:\\\\Users\\\\natha\\\\PycharmProjects\\\\gambling_premises_uk\\\\config\\\\2024_premises-licence-register_metadata.json'\n",
    "\n",
    "with open(path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path ='C:\\\\Users\\\\natha\\\\.cache\\\\kagglehub\\\\datasets\\\\nathanhg\\\\uk-gam-datasets\\\\versions\\\\1'\n",
    "premises = '2024_premises-licence-register.csv'\n",
    "\n",
    "# Read files into memory \n",
    "\n",
    "premises_df = pd.read_csv(os.path.join(path,premises))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check column count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All columns included in imputation rules\n"
     ]
    }
   ],
   "source": [
    "df = premises_df\n",
    "# log discrepencies\n",
    "columns_included = len(data['imputation_rules'].keys())\n",
    "columns_expected = len(df.columns)\n",
    "if columns_expected - columns_expected != 0:\n",
    "    print('Analyst has not included all columns in imputation rules')\n",
    "else:\n",
    "    print('All columns included in imputation rules')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def header_standardization(df):\n",
    "    \"\"\"\n",
    "    Standardizes column names based on BigQuery lexical structure and syntax:\n",
    "    https://cloud.google.com/bigquery/docs/reference/standard-sql/lexical#column_names\n",
    "    Column names are changed if they violate the rules.\n",
    "    \n",
    "    Parameters:\n",
    "        column_names (list): The list of original column names to standardize.\n",
    "    \n",
    "    Returns:\n",
    "        list: The list of standardized column names.\n",
    "    \"\"\"\n",
    "    column_names = df.columns\n",
    "    # Define banned prefixes\n",
    "    banned_prefixes = ['_TABLE_', '_FILE_', '_PARTITION', '_ROW_TIMESTAMP', '__ROOT__', '_COLIDENTIFIER']\n",
    "    banned_prefixes = [prefix.lower() for prefix in banned_prefixes]\n",
    "\n",
    "    # Initialize storage for validated column names and duplicates\n",
    "    validated = []\n",
    "    seen = set()\n",
    "\n",
    "    for i, name in enumerate(column_names):\n",
    "        # Ensure name is a string and convert to lowercase\n",
    "        name = str(name).strip().lower()\n",
    "\n",
    "        # Replace spaces with underscores and keep valid characters only\n",
    "        name = re.sub(r'[^a-z0-9_]', '', name.replace(' ', '_'))\n",
    "\n",
    "        # Enforce max length of 300 characters\n",
    "        name = name[:300]\n",
    "\n",
    "        # Handle banned prefixes\n",
    "        for prefix in banned_prefixes:\n",
    "            if name.startswith(prefix):\n",
    "                name = name.replace(prefix, 'default', 1)\n",
    "\n",
    "        # Prepend \"column\" if the name starts with a digit or is empty\n",
    "        if not name or name[0].isdigit():\n",
    "            name = f\"column_{name}\"\n",
    "\n",
    "        # Resolve duplicates by appending a counter\n",
    "        original_name = name\n",
    "        counter = 1\n",
    "        while name in seen:\n",
    "            name = f\"{original_name}_{counter}\"\n",
    "            counter += 1\n",
    "\n",
    "        # Add the standardized name to the result and mark it as seen\n",
    "        validated.append(name)\n",
    "        seen.add(name)\n",
    "    df.columns = validated\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_and_impute_data(df, metadata):\n",
    "    \"\"\"\n",
    "    Cleans and imputes data based on provided metadata.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame to process.\n",
    "        metadata (dict): Metadata for cleaning, specifying column types and imputation strategies.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: The cleaned and imputed DataFrame.\n",
    "    \"\"\"\n",
    "    for column, rules in metadata.items():\n",
    "        col_type = rules.get(\"type\")\n",
    "        impute_method = rules.get(\"method\")\n",
    "        reference_column = rules.get(\"reference_column\")\n",
    "\n",
    "        # Handle data type conversions based on rules\n",
    "        if col_type == \"categorical\":\n",
    "            if df[column].dtype != 'object':  # Only convert if not already a string\n",
    "                df[column] = df[column].astype(str)\n",
    "                print(f'{column} converted to string')\n",
    "        elif col_type == \"numeric\":\n",
    "            if df[column].dtype != 'float64':  # Only convert if not already numeric\n",
    "                df[column] = pd.to_numeric(df[column], errors='coerce')\n",
    "                print(f'{column} converted to numeric')\n",
    "        elif col_type == \"datetime\":\n",
    "            if df[column].dtype != 'datetime64[ns]':  # Check if already datetime\n",
    "                df[column] = pd.to_datetime(df[column], format='%Y-%m-%d %H:%M:%S', errors='coerce')\n",
    "                print(f'{column} converted to datetime')\n",
    "        elif col_type == \"date\":\n",
    "            if not pd.api.types.is_datetime64_any_dtype(df[column]):  # Check for datetime type first\n",
    "                df[column] = pd.to_datetime(df[column], format='%Y-%m-%d', errors='coerce').dt.date\n",
    "                print(f'{column} converted to date')\n",
    "\n",
    "        # Impute missing values based on specified method\n",
    "        if impute_method == \"NMAR\":\n",
    "            df.fillna({column:\"Missing\"}, inplace=True)\n",
    "            print(f'Filled nulls in {column} with \"Missing\"')\n",
    "        elif impute_method == \"MAR\":\n",
    "            if reference_column:\n",
    "                # Use the reference column to fill missing values\n",
    "                df[column] = df.groupby(reference_column)[column].transform(\n",
    "                    lambda x: x.ffill().bfill() if x.isnull().any() else x\n",
    "                )\n",
    "                print(f'Filled nulls in {column} using forward/backward fill based on {reference_column}')\n",
    "            else:\n",
    "                print(f'Skipping imputation for {column} due to missing reference_column')\n",
    "        else:\n",
    "            print(f'No imputation strategy specified for {column}')\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_standardization(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['address_line_2'].isna()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "account_number converted to numeric\n",
      "Filled nulls in account_number using forward/backward fill based on account_name\n",
      "Filled nulls in account_name using forward/backward fill based on account_number\n",
      "Filled nulls in premises_activity with \"Missing\"\n",
      "Filled nulls in local_authority with \"Missing\"\n",
      "Filled nulls in address_line_1 with \"Missing\"\n",
      "Filled nulls in address_line_2 with \"Missing\"\n",
      "Filled nulls in city using forward/backward fill based on account_number\n",
      "Filled nulls in postcode using forward/backward fill based on account_number\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_and_impute_data(df,data['imputation_rules'])\n",
    "df[df['address_line_2'].isna()].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'deduplicate': True}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['deduplication_rules']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2660"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deduplicate(df, metadata):\n",
    "    \"\"\"\n",
    "    Handles deduplication for the entire dataset based on metadata.\n",
    "    Checks for duplicates before attempting to drop any.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame.\n",
    "        metadata (dict): Metadata defining deduplication rules.\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame after applying deduplication rules.\n",
    "    \"\"\"\n",
    "    deduplication_required = metadata.get(\"deduplication_rules\", {}).get(\"deduplicate\", False)\n",
    "    if deduplication_required:\n",
    "        # Check if there are any duplicate rows in the DataFrame\n",
    "        duplicate_count = df.duplicated().sum()\n",
    "        \n",
    "        if duplicate_count > 0:\n",
    "            # If duplicates are found, drop them\n",
    "            df = df.drop_duplicates(keep=\"first\")\n",
    "            print(f\"Dropped {duplicate_count} duplicate rows.\")\n",
    "    else:\n",
    "        print(\"No duplicates to drop.\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicates to drop.\n"
     ]
    }
   ],
   "source": [
    "deduplicate(df,data['deduplication_rules'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'premises_activity': {'Casino 2005': 'Casino'},\n",
       " 'address_line_1': {\"caesar's palace\": 'caesars palace',\n",
       "  'boylesport': 'boylesports',\n",
       "  'coastal amusements limited': 'coastal amusements',\n",
       "  'carousel amusements limited': 'carousel amusements',\n",
       "  'blue anchor leisure limited': 'blue anchor leisure',\n",
       "  'betting shop operations limited': 'betting shop operations',\n",
       "  'betextra': 'bet extra',\n",
       "  'betszone': 'betzone',\n",
       "  'a & s leisure group limited': 'a & s leisure group',\n",
       "  'a & s leisure': 'a & s leisure group',\n",
       "  'cashino gaming limited': 'cashino gaming'},\n",
       " 'address_line_2': {'coral island, unit 2 promenade': 'coral island, unit 2, promenade',\n",
       "  '98a -99 high street, gorleston': '98a-99 high street, gorleston',\n",
       "  '36 -42 marine terrace ': '36-42 marine terrace'},\n",
       " 'city': {'Middlesborough': 'Middlesbrough',\n",
       "  'Burton-on-trent': 'Burton-upon-trent',\n",
       "  'Blaydon-777upon-tyne': 'Blaydon-on-tyne',\n",
       "  'Bury': 'Bury st. edmunds',\n",
       "  'Lytham': 'Lytham st. annes',\n",
       "  'Richmond': 'Richmond-upon-thames'}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['replacement_rules']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_strings(input_logger,df, df_name, metadata):\n",
    "    \"\"\"\n",
    "    Cleans string columns in a DataFrame by applying deduplication rules and logging changes.\n",
    "    Generates a cleaning audit DataFrame with details of changes.\n",
    "\n",
    "    Args:\n",
    "        input_logger (logging.Logger): Logger for logging info and debug messages.\n",
    "        df (pd.DataFrame): The input DataFrame to clean.\n",
    "        df_name (str): Name of the DataFrame for logging purposes.\n",
    "        metadata (dict): Dictionary with deduplication rules per column.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Cleaned DataFrame.\n",
    "        pd.DataFrame: Cleaning audit DataFrame with columns: ['column', 'old_value', 'new_value', 'occurrences', 'status'].\n",
    "    \"\"\"\n",
    "    input_logger.info(f\"----------- Checking for deduplication {df_name} ---------\")\n",
    "    audit_data = []\n",
    "\n",
    "    for column, replacements in (metadata or {}).items():\n",
    "        if column not in df.columns:\n",
    "            input_logger.warning(f\"Column '{column}' not found in DataFrame. Skipping...\")\n",
    "            continue\n",
    "\n",
    "        df[column] = df[column].astype(str).apply(lambda x: x.strip().lower())\n",
    "\n",
    "        for old_value, new_value in replacements.items():\n",
    "            old_value = old_value.strip().lower()\n",
    "            new_value = new_value.strip().lower()\n",
    "            occurrences = (df[column] == old_value).sum()\n",
    "            status = \"Not Replaced\" if occurrences == 0 else \"Replaced\"\n",
    "\n",
    "            audit_data.append({\n",
    "                \"column\": column,\n",
    "                \"old_value\": old_value,\n",
    "                \"new_value\": new_value,\n",
    "                \"occurrences\": occurrences,\n",
    "                \"status\": status\n",
    "            })\n",
    "\n",
    "            if occurrences > 0:\n",
    "                df[column] = df[column].replace({old_value: new_value.title()}, regex=True)\n",
    "\n",
    "    audit_df = pd.DataFrame(audit_data)\n",
    "    input_logger.info('Completed all replacements.')\n",
    "\n",
    "    return audit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "import os\n",
    "import json\n",
    "\n",
    "def read_gcs_file(bucket_name, blob_name):\n",
    "    \"\"\"Write and read a blob from GCS using file-like IO\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(blob_name)\n",
    "    print(f\"----------- Reading {blob_name} from GCS ---------\")\n",
    "    with blob.open(\"r\" ) as f:  #encoding=\"utf-8\" add if needed here\n",
    "        if \".csv\" in blob_name:\n",
    "            try:\n",
    "                df = pd.read_csv(f,encoding=\"utf-8\")\n",
    "                print(\"Successfully read CSV file to pd.DataFrame\")\n",
    "                return df\n",
    "            except Exception as e:\n",
    "                 print(f\"Unsuccessful CSV read to pd.DataFrame. {e}\")\n",
    "        \n",
    "        elif \".xlsx\" in blob_name:\n",
    "            try:\n",
    "                df = pd.read_excel(f,encoding=\"utf-8\")\n",
    "                print(\"Successfully read XLSX file to pd.DataFrame\")\n",
    "                return df\n",
    "            except Exception as e:\n",
    "                 print(f\"Unsuccessful XLSX read to pd.DataFrame. {e}\")\n",
    "    \n",
    "        elif \".json\" in blob_name:\n",
    "            try:\n",
    "                json_data = json.load(f)\n",
    "                print(\"Successfully read JSON file to memory\")\n",
    "                return json_data\n",
    "            except Exception as e:\n",
    "                print(f\"Unsuccessful JSON read {e}\")\n",
    "        else:\n",
    "            print(f\"The blob_name must be a '.csv', an '.xlsx' or a '.json' file\")\n",
    "            return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------- Reading META/2024_premises-licence-register_metadata.json from GCS ---------\n",
      "Successfully read JSON file to memory\n"
     ]
    }
   ],
   "source": [
    "bucketname = ''\n",
    "name = '2024_premises-licence-register'\n",
    "meta_directory = \"META\"\n",
    "meta_tag = \"_metadata.json\"\n",
    "\n",
    "# read_gcs_file(bucketname,'META/2024_premises-licence-register_metadata.json')\n",
    "meta = read_gcs_file(bucketname,os.path.join(meta_directory, f\"{name}{meta_tag}\").replace(\"\\\\\", \"/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUDITS/combined_audit\n",
      "----------- Reading AUDITS/combined_audit.csv from GCS ---------\n",
      "Successfully read CSV file to pd.DataFrame\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>table</th>\n",
       "      <th>column</th>\n",
       "      <th>action</th>\n",
       "      <th>original_value</th>\n",
       "      <th>new_value</th>\n",
       "      <th>occurrences</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024_premises-licence-register</td>\n",
       "      <td>premises_activity</td>\n",
       "      <td>string_replacement</td>\n",
       "      <td>casino 2005</td>\n",
       "      <td>casino</td>\n",
       "      <td>1</td>\n",
       "      <td>Replaced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024_premises-licence-register</td>\n",
       "      <td>address_line_1</td>\n",
       "      <td>string_replacement</td>\n",
       "      <td>caesar's palace</td>\n",
       "      <td>caesars palace</td>\n",
       "      <td>1</td>\n",
       "      <td>Replaced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024_premises-licence-register</td>\n",
       "      <td>address_line_1</td>\n",
       "      <td>string_replacement</td>\n",
       "      <td>boylesport</td>\n",
       "      <td>boylesports</td>\n",
       "      <td>1</td>\n",
       "      <td>Replaced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2024_premises-licence-register</td>\n",
       "      <td>address_line_1</td>\n",
       "      <td>string_replacement</td>\n",
       "      <td>coastal amusements limited</td>\n",
       "      <td>coastal amusements</td>\n",
       "      <td>10</td>\n",
       "      <td>Replaced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2024_premises-licence-register</td>\n",
       "      <td>address_line_1</td>\n",
       "      <td>string_replacement</td>\n",
       "      <td>carousel amusements limited</td>\n",
       "      <td>carousel amusements</td>\n",
       "      <td>1</td>\n",
       "      <td>Replaced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024_premises-licence-register</td>\n",
       "      <td>address_line_1</td>\n",
       "      <td>string_replacement</td>\n",
       "      <td>blue anchor leisure limited</td>\n",
       "      <td>blue anchor leisure</td>\n",
       "      <td>1</td>\n",
       "      <td>Replaced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2024_premises-licence-register</td>\n",
       "      <td>address_line_1</td>\n",
       "      <td>string_replacement</td>\n",
       "      <td>betting shop operations limited</td>\n",
       "      <td>betting shop operations</td>\n",
       "      <td>9</td>\n",
       "      <td>Replaced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2024_premises-licence-register</td>\n",
       "      <td>address_line_1</td>\n",
       "      <td>string_replacement</td>\n",
       "      <td>betextra</td>\n",
       "      <td>bet extra</td>\n",
       "      <td>1</td>\n",
       "      <td>Replaced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2024_premises-licence-register</td>\n",
       "      <td>address_line_1</td>\n",
       "      <td>string_replacement</td>\n",
       "      <td>betszone</td>\n",
       "      <td>betzone</td>\n",
       "      <td>1</td>\n",
       "      <td>Replaced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024_premises-licence-register</td>\n",
       "      <td>address_line_1</td>\n",
       "      <td>string_replacement</td>\n",
       "      <td>a &amp; s leisure group limited</td>\n",
       "      <td>a &amp; s leisure group</td>\n",
       "      <td>1</td>\n",
       "      <td>Replaced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2024_premises-licence-register</td>\n",
       "      <td>address_line_1</td>\n",
       "      <td>string_replacement</td>\n",
       "      <td>a &amp; s leisure</td>\n",
       "      <td>a &amp; s leisure group</td>\n",
       "      <td>4</td>\n",
       "      <td>Replaced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2024_premises-licence-register</td>\n",
       "      <td>address_line_1</td>\n",
       "      <td>string_replacement</td>\n",
       "      <td>cashino gaming limited</td>\n",
       "      <td>cashino gaming</td>\n",
       "      <td>90</td>\n",
       "      <td>Replaced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2024_premises-licence-register</td>\n",
       "      <td>address_line_2</td>\n",
       "      <td>string_replacement</td>\n",
       "      <td>coral island, unit 2 promenade</td>\n",
       "      <td>coral island, unit 2, promenade</td>\n",
       "      <td>1</td>\n",
       "      <td>Replaced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2024_premises-licence-register</td>\n",
       "      <td>address_line_2</td>\n",
       "      <td>string_replacement</td>\n",
       "      <td>98a -99 high street, gorleston</td>\n",
       "      <td>98a-99 high street, gorleston</td>\n",
       "      <td>1</td>\n",
       "      <td>Replaced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2024_premises-licence-register</td>\n",
       "      <td>address_line_2</td>\n",
       "      <td>string_replacement</td>\n",
       "      <td>36 -42 marine terrace</td>\n",
       "      <td>36-42 marine terrace</td>\n",
       "      <td>1</td>\n",
       "      <td>Replaced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2024_premises-licence-register</td>\n",
       "      <td>city</td>\n",
       "      <td>string_replacement</td>\n",
       "      <td>middlesborough</td>\n",
       "      <td>middlesbrough</td>\n",
       "      <td>1</td>\n",
       "      <td>Replaced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2024_premises-licence-register</td>\n",
       "      <td>city</td>\n",
       "      <td>string_replacement</td>\n",
       "      <td>burton-on-trent</td>\n",
       "      <td>burton-upon-trent</td>\n",
       "      <td>1</td>\n",
       "      <td>Replaced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2024_premises-licence-register</td>\n",
       "      <td>city</td>\n",
       "      <td>string_replacement</td>\n",
       "      <td>blaydon-upon-tyne</td>\n",
       "      <td>blaydon-on-tyne</td>\n",
       "      <td>1</td>\n",
       "      <td>Replaced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2024_premises-licence-register</td>\n",
       "      <td>city</td>\n",
       "      <td>string_replacement</td>\n",
       "      <td>bury</td>\n",
       "      <td>bury st. edmunds</td>\n",
       "      <td>9</td>\n",
       "      <td>Replaced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2024_premises-licence-register</td>\n",
       "      <td>city</td>\n",
       "      <td>string_replacement</td>\n",
       "      <td>lytham</td>\n",
       "      <td>lytham st. annes</td>\n",
       "      <td>1</td>\n",
       "      <td>Replaced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2024_premises-licence-register</td>\n",
       "      <td>city</td>\n",
       "      <td>string_replacement</td>\n",
       "      <td>richmond</td>\n",
       "      <td>richmond-upon-thames</td>\n",
       "      <td>1</td>\n",
       "      <td>Replaced</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             table             column              action  \\\n",
       "0   2024_premises-licence-register  premises_activity  string_replacement   \n",
       "1   2024_premises-licence-register     address_line_1  string_replacement   \n",
       "2   2024_premises-licence-register     address_line_1  string_replacement   \n",
       "3   2024_premises-licence-register     address_line_1  string_replacement   \n",
       "4   2024_premises-licence-register     address_line_1  string_replacement   \n",
       "5   2024_premises-licence-register     address_line_1  string_replacement   \n",
       "6   2024_premises-licence-register     address_line_1  string_replacement   \n",
       "7   2024_premises-licence-register     address_line_1  string_replacement   \n",
       "8   2024_premises-licence-register     address_line_1  string_replacement   \n",
       "9   2024_premises-licence-register     address_line_1  string_replacement   \n",
       "10  2024_premises-licence-register     address_line_1  string_replacement   \n",
       "11  2024_premises-licence-register     address_line_1  string_replacement   \n",
       "12  2024_premises-licence-register     address_line_2  string_replacement   \n",
       "13  2024_premises-licence-register     address_line_2  string_replacement   \n",
       "14  2024_premises-licence-register     address_line_2  string_replacement   \n",
       "15  2024_premises-licence-register               city  string_replacement   \n",
       "16  2024_premises-licence-register               city  string_replacement   \n",
       "17  2024_premises-licence-register               city  string_replacement   \n",
       "18  2024_premises-licence-register               city  string_replacement   \n",
       "19  2024_premises-licence-register               city  string_replacement   \n",
       "20  2024_premises-licence-register               city  string_replacement   \n",
       "\n",
       "                     original_value                        new_value  \\\n",
       "0                       casino 2005                           casino   \n",
       "1                   caesar's palace                   caesars palace   \n",
       "2                        boylesport                      boylesports   \n",
       "3        coastal amusements limited               coastal amusements   \n",
       "4       carousel amusements limited              carousel amusements   \n",
       "5       blue anchor leisure limited              blue anchor leisure   \n",
       "6   betting shop operations limited          betting shop operations   \n",
       "7                          betextra                        bet extra   \n",
       "8                          betszone                          betzone   \n",
       "9       a & s leisure group limited              a & s leisure group   \n",
       "10                    a & s leisure              a & s leisure group   \n",
       "11           cashino gaming limited                   cashino gaming   \n",
       "12   coral island, unit 2 promenade  coral island, unit 2, promenade   \n",
       "13   98a -99 high street, gorleston    98a-99 high street, gorleston   \n",
       "14            36 -42 marine terrace             36-42 marine terrace   \n",
       "15                   middlesborough                    middlesbrough   \n",
       "16                  burton-on-trent                burton-upon-trent   \n",
       "17                blaydon-upon-tyne                  blaydon-on-tyne   \n",
       "18                             bury                 bury st. edmunds   \n",
       "19                           lytham                 lytham st. annes   \n",
       "20                         richmond             richmond-upon-thames   \n",
       "\n",
       "    occurrences    status  \n",
       "0             1  Replaced  \n",
       "1             1  Replaced  \n",
       "2             1  Replaced  \n",
       "3            10  Replaced  \n",
       "4             1  Replaced  \n",
       "5             1  Replaced  \n",
       "6             9  Replaced  \n",
       "7             1  Replaced  \n",
       "8             1  Replaced  \n",
       "9             1  Replaced  \n",
       "10            4  Replaced  \n",
       "11           90  Replaced  \n",
       "12            1  Replaced  \n",
       "13            1  Replaced  \n",
       "14            1  Replaced  \n",
       "15            1  Replaced  \n",
       "16            1  Replaced  \n",
       "17            1  Replaced  \n",
       "18            9  Replaced  \n",
       "19            1  Replaced  \n",
       "20            1  Replaced  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'combined_audit'\n",
    "meta_directory = \"AUDITS\" \n",
    "extension = '.csv'\n",
    "\n",
    "print(os.path.join(meta_directory, f\"{name}\").replace(\"\\\\\", \"/\"))\n",
    "read_gcs_file(bucketname,os.path.join(meta_directory,f\"{name}{extension}\").replace(\"\\\\\", \"/\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v_env_folder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
